import wandb
import torch
from torch.utils.tensorboard import SummaryWriter
import torch.nn as nn
from os.path import join as pjoin

import os
import time
import numpy as np
from collections import OrderedDict, defaultdict
from datetime import datetime

#from utils.eval_t2m import evaluation_vae, test_vae
import math
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

import smplx
from torch.cuda.amp import autocast, GradScaler

def save_eval_summary(metrics_dict, save_dir="results", joint_names=None, epoch=None, prefix=""):
    """
    ä¿å­˜è¯„ä¼°ç»“æœçš„summaryå’Œçƒ­åŠ›å›¾
    
    Args:
        metrics_dict: è¯„ä¼°æŒ‡æ ‡å­—å…¸
        save_dir: ä¿å­˜ç›®å½•
        joint_names: å…³èŠ‚åç§°åˆ—è¡¨
        epoch: å½“å‰epochï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ—¶é—´æˆ³
        prefix: æ–‡ä»¶å‰ç¼€ï¼Œç”¨äºåŒºåˆ†ä¸åŒé˜¶æ®µçš„è¯„ä¼°ï¼ˆå¦‚"pretrain", "epoch"ç­‰ï¼‰
    """
    os.makedirs(save_dir, exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶ååç¼€
    if epoch is not None:
        if prefix:
            suffix = f"{prefix}_epoch_{epoch:03d}"
        else:
            suffix = f"epoch_{epoch:03d}"
    else:
        # ä½¿ç”¨æ—¶é—´æˆ³ï¼Œé€‚ç”¨äºè®­ç»ƒå‰è¯„ä¼°
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if prefix:
            suffix = f"{prefix}_{timestamp}"
        else:
            suffix = f"pretrain_{timestamp}"

    # ===== 1. çƒ­åŠ›å›¾ï¼ˆMPJPE per jointï¼‰ =====
    #ric_joint = metrics_dict["ric_mpjpe"]["mpjpe_per_joint"].cpu().numpy()
    rot_joint = metrics_dict["rot_mpjpe"]["mpjpe_per_joint"].cpu().numpy()
    #assert len(ric_joint) == len(joint_names), f"ric: {len(ric_joint)}, namelist: {len(joint_names)}"
    heat_data = [rot_joint]
    heat_labels = ["rot"]

    plt.figure(figsize=(max(10, len(rot_joint) * 0.3), 2.5))
    ax = sns.heatmap(
        heat_data,
        cmap="YlOrRd",
        cbar=True,
        annot=False,
        xticklabels=joint_names if joint_names is not None else [str(i) for i in range(len(rot_joint))],
        yticklabels=heat_labels
    )
    ax.set_title(f"MPJPE per joint (mm) - {suffix}")
    plt.tight_layout()
    heatmap_path = os.path.join(save_dir, f"mpjpe_per_joint_heatmap_{suffix}.png")
    plt.savefig(heatmap_path)
    plt.close()
    print(f"âœ… Saved heatmap to {heatmap_path}")

    # ===== 2. æ‰“å°å’Œä¿å­˜å…¶ä»–æŒ‡æ ‡ =====
    summary_rows = []

    for key, value_dict in metrics_dict.items():
        for subkey, val in value_dict.items():
            if isinstance(val, torch.Tensor):
                val = val.item() if val.dim() == 0 else val.cpu().numpy()
            summary_rows.append({
                "Category": key,
                "Metric": subkey,
                "Value": val
            })

    df_all = pd.DataFrame(summary_rows)

    # ğŸ”¹ åªç”¨äºç»ˆç«¯æ‰“å°ï¼šè·³è¿‡è¿‡é•¿çš„è¡Œ
    df_print = df_all[~df_all["Metric"].isin(["pa_mpjpe_per_joint", "mpjpe_per_joint"])]

    print(f"\nğŸ“Š Evaluation Summary ({suffix}):\n")
    print(df_print.to_string(index=False, float_format=lambda x: "%.3f" % x if isinstance(x, float) else str(x)))

    # ğŸ”¹ ä¿å­˜å…¨éƒ¨å­—æ®µï¼ˆåŒ…æ‹¬å¤§æ•°ç»„ï¼‰
    table_path = os.path.join(save_dir, f"evaluation_summary_{suffix}.csv")
    df_all.to_csv(table_path, index=False)
    print(f"âœ… Saved evaluation summary table to {table_path}")

@torch.no_grad()
def save_eval_visualization_sample(opt, model, val_loader, save_path):
    model.eval()
    for batch_data in val_loader:
        # unpack batch
        motion, rod3_data, mask, lengths = batch_data

        motion = motion.to(opt.device)
        mask = mask.to(opt.device)

        # forward pass
        pred_motion, loss_dict = model.forward(motion, mask)

        # ä¿å­˜ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼ˆindex=0ï¼‰çš„ç»“æœ
        to_save = {
            "input": motion[0].cpu().numpy(),        # [T, D]
            "output": pred_motion[0].cpu().numpy(),  # [T, D]
            "length": lengths[0].item()              # åŸå§‹é•¿åº¦ï¼ˆç”¨äºå˜é•¿åºåˆ—å¯è§†åŒ–æ—¶è£å‰ªï¼‰
        }
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        np.savez(save_path, **to_save)

        print(f"âœ… Saved inference output for visualization to {save_path}")
        break  # åªå¤„ç†ç¬¬ä¸€ä¸ª batch

def print_current_loss(start_time, niter_state, total_niters, losses, epoch=None, sub_epoch=None,
                       inner_iter=None, tf_ratio=None, sl_steps=None):

    def as_minutes(s):
        m = math.floor(s / 60)
        s -= m * 60
        return '%dm %ds' % (m, s)

    def time_since(since, percent):
        now = time.time()
        s = now - since
        es = s / percent
        rs = es - s
        return '%s (- %s)' % (as_minutes(s), as_minutes(rs))


    # Header: epoch/iter info
    if epoch is not None and inner_iter is not None:
        print(f"[Epoch {epoch:02d} | Iter {inner_iter:04d}] ", end='')

    # Progress
    percent = niter_state / total_niters if total_niters > 0 else 0
    progress_info = time_since(start_time, percent)
    print(f"[{niter_state}/{total_niters} ({percent * 100:.1f}%) | Elapsed {progress_info}]", end=' ')

    # Optional: teacher forcing ratio
    if tf_ratio is not None:
        print(f"TF-ratio: {tf_ratio:.3f}", end=' ')
    if sl_steps is not None:
        print(f"SL-steps: {sl_steps}", end=' ')

    # Losses
    if isinstance(losses, dict):
        loss_str = ' | '.join([f"{k}: {v:.4f}" for k, v in losses.items()])
        print(f"| Losses: {loss_str}")
    else:
        print()  # æŸå¤±ä¸ºç©ºæ—¶æ¢è¡Œ

def def_value():
    return 0.0

class VAETrainer:
    def __init__(self, opt, vae, scaler=None):
        self.opt = opt
        self.vae = vae
        self.scaler = scaler
        self.device = opt.device
        self.smplx_model = None
        
        # --- 1. åˆå§‹åŒ–æŸå¤±å‡½æ•° ---
        if opt.is_train:
            self.logger = SummaryWriter(opt.log_dir)
            
            # ã€ä¿®æ”¹ç‚¹ 1ã€‘æ·»åŠ  reduction='none'ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½åœ¨åé¢ç»™æ‰‹æŒ‡åŠ æƒ
            if opt.recon_loss == "mse":
                self.recon_criterion = nn.MSELoss(reduction='none') 
            else:
                self.recon_criterion = nn.L1Loss(reduction='none')

            if opt.mesh_loss == "l1_smooth":
                self.mesh_criterion = nn.SmoothL1Loss(reduction='none')
            elif opt.mesh_loss == "mse": # å…¼å®¹ mse
                self.mesh_criterion = nn.MSELoss(reduction='none')
            else: # é»˜è®¤ l1
                self.mesh_criterion = nn.L1Loss(reduction='none')
        # --- 2. åŠ è½½ SMPL-X æ¨¡å‹ ---
        try:
            self.smplx_model = smplx.create(
                model_path=opt.smplx_model_path,
                model_type='smplx',
                gender='neutral',
                use_pca=False,
                flat_hand_mean=True,
                batch_size=opt.batch_size * opt.max_length,
            ).to(self.device).eval()
        except Exception as e:
            print(f"SMPLXæ¨¡å‹åŠ è½½å¤±è´¥: {e}")

        # --- 3. ã€æ ¸å¿ƒä¿®æ­£ã€‘æ ¹æ®æ¨¡å¼å‡†å¤‡åŸºç¡€å˜é‡ ---
        # æ£€æŸ¥æ˜¯å¦å¤„äºæ‰‹æŒ‡é™ç»´æ¨¡å¼
        is_reduce_dim_mode = hasattr(opt, 'reduce_dim_finger') and opt.reduce_dim_finger
        
        if is_reduce_dim_mode:
            print("VAETrainer: Initializing in HETEROGENEOUS (reduce_dim_finger) mode.")
            # åœ¨æ­¤æ¨¡å¼ä¸‹ï¼Œopt.joint_feature_dims å¿…é¡»å­˜åœ¨
            if not hasattr(opt, 'joint_feature_dims'):
                raise AttributeError("`reduce_dim_finger` is True, but `opt.joint_feature_dims` is not defined in options.")
            joint_dims_for_calc = opt.joint_feature_dims
        else:
            print("VAETrainer: Initializing in UNIFORM (3D axis-angle) mode.")
            # åœ¨ç»Ÿä¸€æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬æ‰‹åŠ¨åˆ›å»º joint_dims åˆ—è¡¨
            joint_dims_for_calc = [3] * opt.joints_num

        # --- 4. å‡†å¤‡ç”¨äº Mesh Loss çš„æ—‹è½¬æ•°æ®ç´¢å¼• ---
        # è¿™ä¸ªé€»è¾‘ç°åœ¨å¯¹ä¸¤ç§æ¨¡å¼éƒ½é€šç”¨
        self.rot_indices = []
        current_idx = 0
        for dim in joint_dims_for_calc:
            # æ—‹è½¬æ€»æ˜¯æ¯ä¸ªå…³èŠ‚ç‰¹å¾çš„å‰3ç»´
            self.rot_indices.extend([current_idx, current_idx + 1, current_idx + 2])
            current_idx += dim

        # --- 5. æ ¹æ® finger_loss_weight è®¾ç½®åŠ æƒæŸå¤± ---
        # æƒé‡ > 1.0 æ—¶æ‰å¯ç”¨åŠ æƒ
        if hasattr(opt, 'finger_loss_weight') and opt.finger_loss_weight != 1.0:
            self.finger_loss_weight = opt.finger_loss_weight
            print(f"VAETrainer: Weighted loss ENABLED with finger_loss_weight = {self.finger_loss_weight}")

            # a. å‡†å¤‡ Reconstruction Loss çš„æ‰‹æŒ‡ç‰¹å¾ç´¢å¼•
            self.rec_finger_indices = []
            current_idx = 0
            for i in range(self.opt.joints_num):
                dim = joint_dims_for_calc[i]
                if i in self.opt.hand_joint_indices:
                    self.rec_finger_indices.extend(range(current_idx, current_idx + dim))
                current_idx += dim
            
            # b. å‡†å¤‡ Mesh Loss çš„æ‰‹éƒ¨é¡¶ç‚¹ç´¢å¼•
            all_verts_list = self.opt.UPPER_BODY_VERTEX + self.opt.LEFT_HAND_VERTEX + self.opt.RIGHT_HAND_VERTEX
            hand_verts_set = set(self.opt.LEFT_HAND_VERTEX + self.opt.RIGHT_HAND_VERTEX)
            hand_vtx_indices_list = [i for i, v_id in enumerate(all_verts_list) if v_id in hand_verts_set]
            self.hand_vertex_indices = torch.tensor(hand_vtx_indices_list, device=self.device, dtype=torch.long)
        else:
            print("VAETrainer: Weighted loss DISABLED.")
            self.finger_loss_weight = 1.0
            self.rec_finger_indices = None
            self.hand_vertex_indices = None
        self.ALL_SELECTED_VERTICES = self.opt.UPPER_BODY_VERTEX + self.opt.LEFT_HAND_VERTEX + self.opt.RIGHT_HAND_VERTEX
        self.body_indices = torch.tensor(
            self.opt.SELECTED_JOINT_INDICES_BODY_ONLY, 
            device=self.device, 
            dtype=torch.long
        )
    # --- æ–°å¢æ–¹æ³•: ç›‘æ§æ½œç©ºé—´åˆ†å¸ƒ ---
    def monitor_latent_stats(self, val_loader):
        self.vae.eval()
        all_valid_z = []
        
        print("ğŸ“Š Monitoring Latent Space Statistics...")
        with torch.no_grad():
            for i, batch_data in enumerate(val_loader):
                # 1. è§£åŒ…æ•°æ®
                motion, lengths = batch_data
                motion = motion.to(self.device)
                lengths = lengths.to(self.device)
                
                # 2. è·å–è¿ç»­æ½œå˜é‡ Z (Continuous Latent)
                # æ³¨æ„ï¼šæ ¹æ®ä½ çš„ VAE ä»£ç ï¼Œencode è¿”å›çš„æ˜¯ (z, loss_dict)
                z, _ = self.vae.encode(motion) # z shape: [B, T, J, D]
                
                # 3. å¤„ç† Padding (å…³é”®æ­¥éª¤ï¼)
                # z çš„æ—¶é—´ç»´åº¦ T åŒ…å«äº† paddingï¼Œå¿…é¡»æ ¹æ® lengths æ©ç æ‰
                B, T, J, D = z.shape
                
                # åˆ›å»º mask: [B, T] -> [B, T, 1, 1]
                mask = (torch.arange(T, device=self.device)[None, :] < lengths[:, None])
                mask = mask.unsqueeze(-1).unsqueeze(-1) # å¹¿æ’­åˆ° J å’Œ D
                
                # 4. æå–æœ‰æ•ˆæ•°æ®
                # masked_select ä¼šæŠŠæ•°æ®å±•å¹³ä¸º [N_total_valid_elements]
                valid_z_batch = torch.masked_select(z, mask)
                
                # ä¸ºäº†èŠ‚çœæ˜¾å­˜ï¼Œè½¬åˆ° CPU å¹¶å­˜å…¥åˆ—è¡¨
                all_valid_z.append(valid_z_batch.cpu())
                
                # ä¸ºäº†é€Ÿåº¦ï¼Œåªç»Ÿè®¡å‰ 20 ä¸ª Batch å°±è¶³å¤Ÿä»£è¡¨åˆ†å¸ƒäº†
                if i > 20: 
                    break
        
        # 5. æ‹¼æ¥æ‰€æœ‰æœ‰æ•ˆæ•°æ®
        if len(all_valid_z) > 0:
            full_z = torch.cat(all_valid_z)
            
            # 6. è®¡ç®—ç»Ÿè®¡é‡
            z_mean = full_z.mean().item()
            z_std = full_z.std().item()
            z_max = full_z.max().item()
            z_min = full_z.min().item()
            
            print(f"   -> Latent Mean: {z_mean:.4f} (Ideal: ~0.0)")
            print(f"   -> Latent Std : {z_std:.4f}  (Ideal: ~1.0)")
            
            return {
                "latent_stats/mean": z_mean,
                "latent_stats/std": z_std,
                "latent_stats/max": z_max,
                "latent_stats/min": z_min
            }
        else:
            return {}
    # --- åœ¨ VAETrainer ç±»å†…éƒ¨ ---
    def eval_process(self, evaluator, val_loader, selected_names, epoch, it): # å¢åŠ  it 
        print("starting eval")
        # 1. åŸæœ‰çš„è¯„ä¼°é€»è¾‘ (Reconstruction Metrics)
        evaluation_results = evaluator.calculate_metrics(self.vae, val_loader, self.smplx_model)
        # --- W&B è®°å½•è¯¦ç»†è¯„ä¼°æŒ‡æ ‡ (åœ¨è¿™é‡Œæ·»åŠ æ–°ä»£ç ) ---
        eval_log_dict = {}
        # å±•å¹³åµŒå¥—çš„å­—å…¸ä»¥æ–¹ä¾¿è®°å½•
        for key, value_dict in evaluation_results.items():
            for subkey, val in value_dict.items():
                # æˆ‘ä»¬åªè®°å½•æ ‡é‡å€¼ï¼Œå¿½ç•¥ per_joint çš„æ•°ç»„
                if "per_joint" not in subkey:
                    metric_name = f"eval/{key}_{subkey}" # e.g., "eval/rot_mpjpe_mpjpe_body"
                    eval_log_dict[metric_name] = val.item() if isinstance(val, torch.Tensor) else val
        # ==================== ã€æ–°å¢ä»£ç å¼€å§‹ã€‘ ====================
        # 2. æ½œç©ºé—´åˆ†å¸ƒæ£€æŸ¥
        latent_stats = self.monitor_latent_stats(val_loader)
        
        # å°† latent ç»Ÿè®¡æ•°æ®åˆå¹¶åˆ° log å­—å…¸ä¸­
        eval_log_dict.update(latent_stats)
        
        # ç®€å•çš„å¥åº·æ£€æŸ¥æŠ¥è­¦ (åœ¨ç»ˆç«¯æ‰“å°è­¦å‘Š)
        if epoch is not None: # åªåœ¨æ­£å¼è®­ç»ƒ eval æ—¶æ£€æŸ¥
            std = latent_stats.get("latent_stats/std", 1.0)
            if std > 1.5 or std < 0.5:
                print(f"âš ï¸ WARNING: Latent STD is abnormal ({std:.4f})! Diffusion model training might fail.")
                print(f"   Suggestion: Adjust KL weight (lambda_kl) or check input normalization.")
        # ==================== ã€æ–°å¢ä»£ç ç»“æŸã€‘ ====================
        
        wandb.log(eval_log_dict, step=it)

        # æ³¨æ„ï¼šè¿™é‡Œçš„ save_eval_summary ä¼šç”Ÿæˆä¸€ä¸ªçƒ­åŠ›å›¾
        # æˆ‘ä»¬å¯ä»¥é¡ºä¾¿æŠŠè¿™ä¸ªå›¾ä¹Ÿä¸Šä¼ åˆ° wandb
        save_dir = self.opt.save_root
        if epoch is None:
            prefix = "pretrain"
        else:
            prefix = "eval"

        save_eval_summary(
            metrics_dict=evaluation_results,
            save_dir=save_dir,
            joint_names=selected_names,
            epoch=epoch,
            prefix=prefix
        )

        # ä» save_eval_summary è·å– heatmap è·¯å¾„å¹¶ä¸Šä¼ 
        # (è¿™éƒ¨åˆ†é€»è¾‘éœ€è¦ä¸ save_eval_summary å†…éƒ¨çš„æ–‡ä»¶åç”Ÿæˆé€»è¾‘ä¿æŒä¸€è‡´)
        if epoch is None:
             # å¯¹äº pretrainï¼Œsave_eval_summary ä½¿ç”¨æ—¶é—´æˆ³ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥é¢„æµ‹æ–‡ä»¶å
             # æœ€ç®€å•çš„åŠæ³•æ˜¯å‡è®¾åªæœ‰ä¸€ä¸ª pretrain heatmapï¼Œæˆ–è€…ä¿®æ”¹ save_eval_summary è¿”å›è·¯å¾„
             # ä¸ºç®€å•èµ·è§ï¼Œè¿™é‡Œæˆ‘ä»¬æš‚æ—¶åªä¸Šä¼  epoch > 0 æ—¶çš„ heatmap
             pass
        else:
            suffix = f"{prefix}_epoch_{epoch:03d}"
            heatmap_path = os.path.join(save_dir, f"mpjpe_per_joint_heatmap_{suffix}.png")
            if os.path.exists(heatmap_path):
                wandb.log({"eval/MPJPE_Heatmap": wandb.Image(heatmap_path)}, step=it)

    def train_forward(self, batch_data, epoch):
        # 1. è§£åŒ…æ•°æ®å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
        motion, lengths = batch_data  # motion:[B, T, D_flat], lengths:[B]
        motion = motion.to(self.opt.device)
        lengths = lengths.to(self.opt.device)
        B, T, D_flat = motion.shape 
        
        # 2. VAE å‰å‘ä¼ æ’­ (Dual Path)
        # è¿”å›: è¿ç»­è¾“å‡º, é‡åŒ–è¾“å‡º, è¿ç»­Z, é‡åŒ–Z, æŸå¤±å­—å…¸
        out_cont, out_quant, z_cont, z_quant, loss_dict = self.vae(motion)

        # ==================== ã€å®Œæ•´ç‰ˆ: Codebook Reset æœºåˆ¶ã€‘ ====================
        # ç­–ç•¥ï¼šåˆ©ç”¨å½“å‰ Batch ä¸°å¯Œçš„ z_cont ç‰¹å¾æ¥æ¿€æ´»æ­»ç 
        # è§¦å‘é¢‘ç‡ï¼šçº¦æ¯ 50 ä¸ª Batch è§¦å‘ä¸€æ¬¡ (æ¦‚ç‡ 0.02)
        if self.vae.training and torch.rand(1).item() < 0.02:
            with torch.no_grad():
                # ç›´æ¥æŠŠå®Œæ•´çš„ z_cont ä¼ è¿›å»ï¼ŒModel è‡ªå·±çŸ¥é“æ€ä¹ˆåˆ‡
                n_total, stats = self.vae.reset_all_codebooks(z_cont)
                
                if n_total > 0:
                    # Optional: æ‰“å°é‡ç½®è¯¦æƒ…
                    msg = ", ".join([f"{k}:{v}" for k,v in stats.items()])
                    print(f"[Reset] {msg}")
                    pass
        # =======================================================================

        # 3. åˆ›å»º Mask
        mask = torch.arange(T, device=self.opt.device)[None, :] < lengths[:, None]
        N_frames = B * T
        
        # 4. å‡†å¤‡ Ground Truth çš„ SMPL-X æ•°æ® (å®Œæ•´è¡¥å…¨)
        # ---------------------------------------------------------
        if self.opt.data_format == 'motion_dataset_rod3_fixed_length_dk':
            gt_rot = motion[:, :, self.rot_indices]
            all_gt = gt_rot.reshape(N_frames, self.opt.joints_num, 3).contiguous()
        else:
            all_gt = motion.reshape(N_frames, self.opt.joints_num, 3).contiguous()

        # å®šä¹‰åˆ‡åˆ†å‡½æ•° (å¤ç”¨)
        def split_smplx_local(x):
            # x shape: [N_frames, J, 3]
            body = x[:, :13]   # 0-12
            lhand = x[:, 13:28] # 13-27
            rhand = x[:, 28:43] # 28-42
            
            # è¿˜åŸåˆ° SMPL-X å®Œæ•´å…³èŠ‚ (22ä¸ªèº«ä½“ + æ‰‹)
            restored = torch.zeros(x.shape[0], 22, 3, device=self.device, dtype=x.dtype)
            restored[:, self.body_indices] = body 
            # è¿”å›: body(æ’é™¤root), lhand, rhand
            return restored[:, 1:], lhand, rhand

        # è®¡ç®— GT Vertices
        gt_body, gt_lh, gt_rh = split_smplx_local(all_gt)
        with torch.no_grad():
            out_gt = self.smplx_model(body_pose=gt_body, left_hand_pose=gt_lh, right_hand_pose=gt_rh)
        
        # æå– GT é¡¶ç‚¹å¹¶ Reshape [B, T, V, 3]
        verts_gt_full = out_gt.vertices[:, self.ALL_SELECTED_VERTICES, :].reshape(B, T, -1, 3)
        valid_verts_gt = verts_gt_full[mask] # [N_valid, V, 3]
        # ---------------------------------------------------------

        # 5. å®šä¹‰è®¡ç®— Mesh Loss çš„é—­åŒ… (ç”¨äº Cont å’Œ Quant ä¸¤è·¯)
        def compute_weighted_mesh_loss(pred_motion):
            # a. Reshape
            if self.opt.data_format == 'motion_dataset_rod3_fixed_length_dk':
                pred_rot = pred_motion[:, :, self.rot_indices]
                all_pred = pred_rot.reshape(N_frames, self.opt.joints_num, 3).contiguous()
            else:
                all_pred = pred_motion.reshape(N_frames, self.opt.joints_num, 3).contiguous()
            
            # b. Split & Forward
            pd_body, pd_lh, pd_rh = split_smplx_local(all_pred)
            out_pd = self.smplx_model(body_pose=pd_body, left_hand_pose=pd_lh, right_hand_pose=pd_rh)
            verts_pd = out_pd.vertices[:, self.ALL_SELECTED_VERTICES, :].reshape(B, T, -1, 3)
            
            # c. Masking
            valid_verts_pd = verts_pd[mask] # [N_valid, V, 3]
            
            # ==================== ã€ä¿®æ”¹ç‚¹ 2 STARTã€‘ ====================
            # d. Error Calculation (ç›´æ¥ä½¿ç”¨ init é‡Œå®šä¹‰çš„ loss å‡½æ•°)
            # å› ä¸ºæˆ‘ä»¬è®¾ç½®äº† reduction='none'ï¼Œè¿™é‡Œè¿”å›çš„ error å½¢çŠ¶å’Œè¾“å…¥ä¸€æ ·ï¼Œæ˜¯ [N_valid, V, 3]
            error = self.mesh_criterion(valid_verts_pd, valid_verts_gt)
            # ==================== ã€ä¿®æ”¹ç‚¹ 2 ENDã€‘ ====================
            
            # e. Weighting (æ‰‹æŒ‡åŠ æƒ)
            if self.opt.finger_loss_weight != 1.0:
                # æ„é€ æƒé‡: [1, N_verts, 1]
                weights = torch.ones(valid_verts_pd.shape[1], device=self.device)
                weights[self.hand_vertex_indices] = self.finger_loss_weight
                weights = weights.view(1, -1, 1)
                return (error * weights).mean()
            else:
                return error.mean()

        # 6. è®¡ç®—åŒè·¯ Reconstruction Loss
        loss_mesh_cont = compute_weighted_mesh_loss(out_cont)
        
        # å…³é”®ï¼šé‡åŒ–è·¯ä¹Ÿè¦ç®— Mesh Lossï¼Œè¿™æ · Decoder æ‰ä¼šå»é€‚åº” z_q
        loss_mesh_quant = compute_weighted_mesh_loss(out_quant)

        # 7. è®¡ç®—ä¸€è‡´æ€§æŸå¤± (Consistency Loss)
        # -----------------------------------------------------------
        # A. Latent Consistency (Commitment): 
        #    æ‹‰è¿‘ z_cont å’Œ z_quantã€‚
        #    detach() æ˜¯æ ‡å‡†æ“ä½œï¼šåªæ‹‰åŠ¨ Encoder (z_cont) å»é è¿‘ Codebook (z_quant)ï¼Œ
        #    è€Œä¸å¸Œæœ›æŠŠ Codebook æ‹‰ä¹± (Codebook æ›´æ–°ç”± Quantizer å†…éƒ¨ loss è´Ÿè´£)ã€‚
        loss_latent_consist = torch.mean((z_cont - z_quant.detach())**2)
        
        # B. Output Consistency (Self-Distillation):
        #    è®© Quantized Output å»æ¨¡ä»¿ Continuous Outputã€‚
        #    è¿™æ¯”å•çº¯æ¨¡ä»¿ GT æ›´å®¹æ˜“ï¼Œå› ä¸º Continuous Output åŒ…å«äº†æ¨¡å‹è‡ªèº«çš„åç½®ï¼Œ
        #    è¿™èƒ½è®©é‡åŒ–è·¯æ›´å¿«æ”¶æ•›ã€‚
        #loss_output_consist = torch.mean((out_quant - out_cont.detach())**2)
        # -----------------------------------------------------------

        # 8. æ±‡æ€» Loss
        loss_kl = loss_dict["loss_kl"]
        loss_quant = loss_dict.get("loss_quant", 0.0) # åŒ…å« embedding loss
        
        # æƒé‡é…ç½® (å»ºè®®æ”¾å…¥ opt)
        w_q_recon = getattr(self.opt, 'lambda_q_recon', 1.0)
        w_consist = getattr(self.opt, 'lambda_consistency', 0.5)
        w_quant_loss = getattr(self.opt, 'lambda_quant', 1.0)
        
        total_loss = loss_mesh_cont + \
                     (w_q_recon * loss_mesh_quant) + \
                     (w_consist * loss_latent_consist) + \
                     (w_quant_loss * loss_quant) + \
                     (self.opt.lambda_kl * loss_kl)

        # è®°å½•è¯¦ç»† Loss ä¾› W&B ç›‘æ§
        loss_dict["loss_mesh_cont"] = loss_mesh_cont
        loss_dict["loss_mesh_quant"] = loss_mesh_quant
        loss_dict["loss_consist"]   = loss_latent_consist
        loss_dict["loss_total"]     = total_loss
        
        return total_loss, loss_dict

    def update_lr_warm_up(self, nb_iter, warm_up_iter, lr):
        current_lr = lr * (nb_iter + 1) / (warm_up_iter + 1)
        for param_group in self.optim.param_groups:
            param_group["lr"] = current_lr


    def save(self, file_name, epoch, total_iter):
        state = {
            "vae": self.vae.state_dict(),
            "optim": self.optim.state_dict(),
            "scheduler": self.scheduler.state_dict(),
            "epoch": epoch,
            "total_iter": total_iter,
        }
        torch.save(state, file_name)


    def resume(self, model_dir):
        checkpoint = torch.load(model_dir, map_location=self.opt.device)
        self.vae.load_state_dict(checkpoint["vae"])
        self.optim.load_state_dict(checkpoint["optim"])
        self.scheduler.load_state_dict(checkpoint["scheduler"])
        return checkpoint["epoch"], checkpoint["total_iter"]


    def train(self, train_loader, val_loader, evaluator):
        self.vae.to(self.opt.device)

        # optimizer
        self.optim = torch.optim.AdamW(self.vae.parameters(), lr=self.opt.lr, betas=(0.9, 0.99), weight_decay=self.opt.weight_decay)
        self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optim, milestones=self.opt.milestones, gamma=self.opt.gamma)

        epoch = 0
        it = 0
        if self.opt.is_continue:
            model_dir = pjoin(self.opt.model_dir, 'latest.tar')
            epoch, it = self.resume(model_dir)
            print("Load model epoch:%d iterations:%d"%(epoch, it))

        start_time = time.time()
        total_iters = self.opt.max_epoch * len(train_loader)
        print(f'Total Epochs: {self.opt.max_epoch}, Total Iters: {total_iters}')
        print('Iters Per Epoch, Training: %04d, Validation: %03d' % (len(train_loader), len(val_loader)))
        logs = defaultdict(def_value, OrderedDict())
        
        # eval before train - ä½¿ç”¨pretrainå‰ç¼€å’Œæ—¶é—´æˆ³
        selected_names = [self.opt.SMPLX_JOINT_LANDMARK_NAMES[i] for i in self.opt.SELECTED_JOINT_LANDMARK_INDICES]
        self.vae.eval()
        # ã€æœ€ä½³å®è·µã€‘åœ¨è¿™é‡ŒåŒ…è£¹ no_gradï¼Œä»æ ¹æºä¸Šé˜»æ­¢æ¢¯åº¦è®¡ç®—
        with torch.no_grad():
            self.eval_process(evaluator, val_loader, selected_names, None, it)
        
        # è®­ç»ƒå‰è¯„ä¼°ç»“æŸåï¼Œåˆ«å¿˜äº†å°†æ¨¡å‹åˆ‡æ¢å›è®­ç»ƒæ¨¡å¼
        self.vae.train() 
        # training loop
        while epoch < self.opt.max_epoch:
            self.vae.train()
            for i, batch_data in enumerate(train_loader):
                it += 1
                if it < self.opt.warm_up_iter:
                    curr_lr = self.update_lr_warm_up(it, self.opt.warm_up_iter, self.opt.lr)

                # forward
                self.optim.zero_grad()
                with autocast():
                    loss, loss_dict = self.train_forward(batch_data, epoch)


                # --- ã€æ ¸å¿ƒä¿®æ”¹ã€‘æ¢¯åº¦è£å‰ªé€»è¾‘ ---
                # 1. ç…§å¸¸è®¡ç®—ç¼©æ”¾åçš„æ¢¯åº¦
                self.scaler.scale(loss).backward()

                # 2. åœ¨è£å‰ªå‰ï¼Œå¿…é¡»å…ˆ unscale æ¢¯åº¦
                self.scaler.unscale_(self.optim)

                # 3. å¯¹ unscale åçš„æ¢¯åº¦è¿›è¡Œè£å‰ªï¼Œ1.0 æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„æœ€å¤§èŒƒæ•°é˜ˆå€¼
                torch.nn.utils.clip_grad_norm_(self.vae.parameters(), 1.0)

                # 4. ä¼˜åŒ–å™¨æ‰§è¡Œä¸€æ­¥
                self.scaler.step(self.optim)

                # 5. æ›´æ–° scaler çš„ç¼©æ”¾å› å­
                self.scaler.update()
                
                if it >= self.opt.warm_up_iter:
                    self.scheduler.step()
                # --- Codebook Reset Strategy ---
                # æ¯ 500 ä¸ª step æ£€æŸ¥ä¸€æ¬¡
                if it % 500 == 0:
                    # æ”¶é›†å½“å‰ batch çš„ z (ä¸ºäº†ä»ä¸­é‡‡æ ·)
                    # æˆ‘ä»¬éœ€è¦å†æ¬¡ encode ä¸€ä¸‹æˆ–è€…ç¼“å­˜ä¹‹å‰çš„ z
                    # ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ä»å½“å‰ batch é‡æ–° encode
                    with torch.no_grad():
                        # 1. é‡æ–° Encode å½“å‰ batch ä»¥è·å–æœ€æ–°ç‰¹å¾
                        z_curr, _ = self.vae.encode(batch_data[0].to(self.device))
                        
                        # 2. è°ƒç”¨æ¨¡å‹å†…éƒ¨å°è£…å¥½çš„ Reset æ–¹æ³•
                        # å®ƒä¼šè‡ªåŠ¨å¤„ç†æ‰€æœ‰åˆ†ç»„ï¼ˆæ— è®ºæ˜¯ Default, Arm Mirror è¿˜æ˜¯ Finger Distinctï¼‰
                        n_total, stats = self.vae.reset_all_codebooks(z_curr)
                        
                        # 3. æ‰“å°æ—¥å¿—
                        if n_total > 0:
                            msg = ", ".join([f"{k}:{v}" for k,v in stats.items()])
                            print(f"[Iter {it}] Codebook Reset: {msg}")
                for tag, value in loss_dict.items():
                    if isinstance(value, torch.Tensor):
                        logs[tag] += value.item()
                    else:
                        logs[tag] += value

                if it % self.opt.log_every == 0:
                    mean_loss = OrderedDict()
                    for tag, value in logs.items():
                        self.logger.add_scalar('Train/%s'%tag, value / self.opt.log_every, it)
                        mean_loss[tag] = value / self.opt.log_every
                    logs = defaultdict(def_value, OrderedDict())
                    print_current_loss(start_time, it, total_iters, mean_loss, epoch=epoch, inner_iter=i)
                    # --- W&B è®°å½•è®­ç»ƒæŸå¤± (åœ¨è¿™é‡Œæ·»åŠ æ–°ä»£ç ) ---
                    # æ„é€ ä¸€ä¸ªå¸¦ 'train/' å‰ç¼€çš„å­—å…¸å¹¶è®°å½•
                    train_log_dict = {"train/" + k: v for k, v in mean_loss.items()}
                    train_log_dict['lr'] = self.optim.param_groups[0]['lr'] # é¢å¤–è®°å½•å­¦ä¹ ç‡
                    wandb.log(train_log_dict, step=it)
                    # ------------------------------------

                if it % self.opt.save_latest == 0:
                    self.save(pjoin(self.opt.model_dir, 'latest.tar'), epoch, it)

            self.save(pjoin(self.opt.model_dir, 'latest.tar'), epoch, it)

            epoch += 1
            print('Validation time:')
            self.vae.eval()
            val_log = defaultdict(def_value, OrderedDict())
            with torch.no_grad():
                for i, batch_data in enumerate(val_loader):
                    loss, loss_dict = self.train_forward(batch_data,epoch)

                    # ==================== ã€BUG ä¿®å¤åŒº START (é€šç”¨ç‰ˆ)ã€‘ ====================
                    val_log["loss"] += loss.item()
                    for tag, value in loss_dict.items():
                        # --- æ ¸å¿ƒä¿®å¤ 2.0: åŠ¨æ€è¯†åˆ«éæ ‡é‡ ---
                        
                        # 1. å¦‚æœ key åå­—é‡Œæ˜ç¡®å†™äº†æ˜¯ indicesï¼Œç›´æ¥è·³è¿‡
                        if "indices" in tag:
                            continue
                        
                        # 2. åŒé‡ä¿é™©ï¼šæ£€æŸ¥ Tensor çš„ç»´åº¦
                        # å¦‚æœæ˜¯å¼ é‡ä¸”åŒ…å«å¤šäº 1 ä¸ªå…ƒç´ ï¼Œç»å¯¹ä¸èƒ½ .item()
                        if isinstance(value, torch.Tensor):
                            if value.numel() > 1:
                                continue
                            val_log[tag] += value.item()
                        else:
                            val_log[tag] += value
                    # ==================== ã€BUG ä¿®å¤åŒº ENDã€‘ ====================

            
            # --- W&B è®°å½•éªŒè¯æŸå¤± (åœ¨è¿™é‡Œä¿®æ”¹) ---
            # æ„é€ ä¸€ä¸ªå¸¦ 'val/' å‰ç¼€çš„å­—å…¸å¹¶è®°å½•
            val_log_dict = {}
            msg = "Validation loss: "
            for tag, value in val_log.items():
                # --- ä¿®å¤: é™¤ä»¥ len(val_loader) æ¥è·å¾—å¹³å‡å€¼ ---
                avg_val = value / len(val_loader)
                self.logger.add_scalar('Val/%s'%tag, avg_val, epoch)
                msg += "%s: %.8f, " % (tag, avg_val)
                val_log_dict["val/" + tag] = avg_val # å¡«å……å­—å…¸
            print(msg)
            wandb.log(val_log_dict, step=it) # åœ¨è¿­ä»£æ­¥ä¸Šè®°å½•éªŒè¯ç»“æœ
            # mean_loss = OrderedDict() # è¿™ä¸€è¡Œä¼¼ä¹æ˜¯å¤šä½™çš„ï¼Œæ³¨é‡Šæ‰
            # -----------------------------------
            
            # evaluation - ä½¿ç”¨epochä¿¡æ¯
            if epoch % self.opt.eval_every_e == 0:
                self.vae.eval()
                with torch.no_grad():
                    self.eval_process(evaluator, val_loader, selected_names, None, it)
                self.vae.train()
